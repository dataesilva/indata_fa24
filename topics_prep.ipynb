{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Source: https://github.com/susanli2016/Machine-Learning-with-Python/blob/master/topic_modeling_Gensim.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import gensim\n",
    "import nltk\n",
    "import spacy\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\dsilva2\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\dsilva2\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download('wordnet')\n",
    "nltk.download('stopwords')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting en-core-web-sm==3.7.1\n",
      "  Downloading https://github.com/explosion/spacy-models/releases/download/en_core_web_sm-3.7.1/en_core_web_sm-3.7.1-py3-none-any.whl (12.8 MB)\n",
      "     ---------------------------------------- 0.0/12.8 MB ? eta -:--:--\n",
      "     ------ --------------------------------- 2.1/12.8 MB 13.0 MB/s eta 0:00:01\n",
      "     ----------------------- ---------------- 7.6/12.8 MB 20.4 MB/s eta 0:00:01\n",
      "     --------------------------------------- 12.8/12.8 MB 25.9 MB/s eta 0:00:00\n",
      "Requirement already satisfied: spacy<3.8.0,>=3.7.2 in c:\\users\\dsilva2\\anaconda3\\envs\\indata_fa24\\lib\\site-packages (from en-core-web-sm==3.7.1) (3.7.2)\n",
      "Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.11 in c:\\users\\dsilva2\\anaconda3\\envs\\indata_fa24\\lib\\site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (3.0.12)\n",
      "Requirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in c:\\users\\dsilva2\\anaconda3\\envs\\indata_fa24\\lib\\site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (1.0.4)\n",
      "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in c:\\users\\dsilva2\\anaconda3\\envs\\indata_fa24\\lib\\site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (1.0.7)\n",
      "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in c:\\users\\dsilva2\\anaconda3\\envs\\indata_fa24\\lib\\site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (2.0.6)\n",
      "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in c:\\users\\dsilva2\\anaconda3\\envs\\indata_fa24\\lib\\site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (3.0.6)\n",
      "Requirement already satisfied: thinc<8.3.0,>=8.1.8 in c:\\users\\dsilva2\\anaconda3\\envs\\indata_fa24\\lib\\site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (8.2.2)\n",
      "Requirement already satisfied: wasabi<1.2.0,>=0.9.1 in c:\\users\\dsilva2\\anaconda3\\envs\\indata_fa24\\lib\\site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (0.9.1)\n",
      "Requirement already satisfied: srsly<3.0.0,>=2.4.3 in c:\\users\\dsilva2\\anaconda3\\envs\\indata_fa24\\lib\\site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (2.4.8)\n",
      "Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in c:\\users\\dsilva2\\anaconda3\\envs\\indata_fa24\\lib\\site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (2.0.10)\n",
      "Requirement already satisfied: weasel<0.4.0,>=0.1.0 in c:\\users\\dsilva2\\anaconda3\\envs\\indata_fa24\\lib\\site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (0.3.4)\n",
      "Requirement already satisfied: typer<0.10.0,>=0.3.0 in c:\\users\\dsilva2\\anaconda3\\envs\\indata_fa24\\lib\\site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (0.9.0)\n",
      "Requirement already satisfied: smart-open<7.0.0,>=5.2.1 in c:\\users\\dsilva2\\anaconda3\\envs\\indata_fa24\\lib\\site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (5.2.1)\n",
      "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in c:\\users\\dsilva2\\anaconda3\\envs\\indata_fa24\\lib\\site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (4.66.5)\n",
      "Requirement already satisfied: requests<3.0.0,>=2.13.0 in c:\\users\\dsilva2\\anaconda3\\envs\\indata_fa24\\lib\\site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (2.32.3)\n",
      "Requirement already satisfied: pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4 in c:\\users\\dsilva2\\anaconda3\\envs\\indata_fa24\\lib\\site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (2.8.2)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\dsilva2\\anaconda3\\envs\\indata_fa24\\lib\\site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (3.1.4)\n",
      "Requirement already satisfied: setuptools in c:\\users\\dsilva2\\anaconda3\\envs\\indata_fa24\\lib\\site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (72.1.0)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\dsilva2\\anaconda3\\envs\\indata_fa24\\lib\\site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (24.1)\n",
      "Requirement already satisfied: langcodes<4.0.0,>=3.2.0 in c:\\users\\dsilva2\\anaconda3\\envs\\indata_fa24\\lib\\site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (3.3.0)\n",
      "Requirement already satisfied: numpy>=1.19.0 in c:\\users\\dsilva2\\anaconda3\\envs\\indata_fa24\\lib\\site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (1.26.4)\n",
      "Requirement already satisfied: annotated-types>=0.4.0 in c:\\users\\dsilva2\\anaconda3\\envs\\indata_fa24\\lib\\site-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (0.6.0)\n",
      "Requirement already satisfied: pydantic-core==2.20.1 in c:\\users\\dsilva2\\anaconda3\\envs\\indata_fa24\\lib\\site-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (2.20.1)\n",
      "Requirement already satisfied: typing-extensions>=4.6.1 in c:\\users\\dsilva2\\anaconda3\\envs\\indata_fa24\\lib\\site-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (4.11.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\dsilva2\\anaconda3\\envs\\indata_fa24\\lib\\site-packages (from requests<3.0.0,>=2.13.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\dsilva2\\anaconda3\\envs\\indata_fa24\\lib\\site-packages (from requests<3.0.0,>=2.13.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\dsilva2\\anaconda3\\envs\\indata_fa24\\lib\\site-packages (from requests<3.0.0,>=2.13.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (2.2.2)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\dsilva2\\anaconda3\\envs\\indata_fa24\\lib\\site-packages (from requests<3.0.0,>=2.13.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (2024.8.30)\n",
      "Requirement already satisfied: blis<0.8.0,>=0.7.8 in c:\\users\\dsilva2\\anaconda3\\envs\\indata_fa24\\lib\\site-packages (from thinc<8.3.0,>=8.1.8->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (0.7.11)\n",
      "Requirement already satisfied: confection<1.0.0,>=0.0.1 in c:\\users\\dsilva2\\anaconda3\\envs\\indata_fa24\\lib\\site-packages (from thinc<8.3.0,>=8.1.8->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (0.1.4)\n",
      "Requirement already satisfied: colorama in c:\\users\\dsilva2\\anaconda3\\envs\\indata_fa24\\lib\\site-packages (from tqdm<5.0.0,>=4.38.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (0.4.6)\n",
      "Requirement already satisfied: click<9.0.0,>=7.1.1 in c:\\users\\dsilva2\\anaconda3\\envs\\indata_fa24\\lib\\site-packages (from typer<0.10.0,>=0.3.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (8.1.7)\n",
      "Requirement already satisfied: cloudpathlib<0.17.0,>=0.7.0 in c:\\users\\dsilva2\\anaconda3\\envs\\indata_fa24\\lib\\site-packages (from weasel<0.4.0,>=0.1.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (0.16.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\dsilva2\\anaconda3\\envs\\indata_fa24\\lib\\site-packages (from jinja2->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (2.1.3)\n",
      "âœ” Download and installation successful\n",
      "You can now load the package via spacy.load('en_core_web_sm')\n"
     ]
    }
   ],
   "source": [
    "! python -m spacy download en_core_web_sm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<spacy.lang.en.English at 0x26eda8cc0b0>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spacy.load(\"en_core_web_sm\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>Title</th>\n",
       "      <th>Url</th>\n",
       "      <th>Language</th>\n",
       "      <th>Author</th>\n",
       "      <th>Avatar</th>\n",
       "      <th>Category Details</th>\n",
       "      <th>Checked</th>\n",
       "      <th>City</th>\n",
       "      <th>Display URLs</th>\n",
       "      <th>...</th>\n",
       "      <th>Twitter Followers</th>\n",
       "      <th>Twitter Following</th>\n",
       "      <th>Twitter Reply Count</th>\n",
       "      <th>Twitter Reply to</th>\n",
       "      <th>Twitter Retweet of</th>\n",
       "      <th>Twitter Retweets</th>\n",
       "      <th>Twitter Tweets</th>\n",
       "      <th>Twitter Verified</th>\n",
       "      <th>Updated</th>\n",
       "      <th>Reach (new)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2020-03-31 23:58:48.0</td>\n",
       "      <td>@TeamUSA Literally all of the 2012 Olympics fo...</td>\n",
       "      <td>http://twitter.com/arv5518/statuses/1245138508...</td>\n",
       "      <td>en</td>\n",
       "      <td>arv5518</td>\n",
       "      <td>https://audiences.brandwatch.com/api/audiences...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>3</td>\n",
       "      <td>76</td>\n",
       "      <td>0</td>\n",
       "      <td>http://twitter.com/TeamUSA/statuses/1245063460...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>345</td>\n",
       "      <td>False</td>\n",
       "      <td>2020-10-05T16:39:32.631+0000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2020-03-31 23:57:17.0</td>\n",
       "      <td>@LanderVBALL @reesebatesvb @vbcoch @USAVBeach ...</td>\n",
       "      <td>http://twitter.com/alexptck3/statuses/12451381...</td>\n",
       "      <td>en</td>\n",
       "      <td>alexptck3</td>\n",
       "      <td>https://audiences.brandwatch.com/api/audiences...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>217</td>\n",
       "      <td>293</td>\n",
       "      <td>1</td>\n",
       "      <td>http://twitter.com/LanderVBALL/statuses/124511...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>1600</td>\n",
       "      <td>False</td>\n",
       "      <td>2020-10-05T16:39:32.613+0000</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2020-03-31 23:57:00.0</td>\n",
       "      <td>\"To be blunt, it started women's basketball in...</td>\n",
       "      <td>http://twitter.com/NBCOlympics/statuses/124513...</td>\n",
       "      <td>en</td>\n",
       "      <td>NBCOlympics</td>\n",
       "      <td>https://audiences.brandwatch.com/api/audiences...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>922572</td>\n",
       "      <td>2991</td>\n",
       "      <td>2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>61</td>\n",
       "      <td>32017</td>\n",
       "      <td>True</td>\n",
       "      <td>2020-10-05T16:39:32.615+0000</td>\n",
       "      <td>67412</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2020-03-31 23:56:25.0</td>\n",
       "      <td>@DetroitHandball @TeamHandball @USATH @USARugb...</td>\n",
       "      <td>http://twitter.com/CoachJax11/statuses/1245137...</td>\n",
       "      <td>en</td>\n",
       "      <td>CoachJax11</td>\n",
       "      <td>https://audiences.brandwatch.com/api/audiences...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>158</td>\n",
       "      <td>249</td>\n",
       "      <td>1</td>\n",
       "      <td>http://twitter.com/DetroitHandball/statuses/12...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>792</td>\n",
       "      <td>False</td>\n",
       "      <td>2020-10-05T16:39:32.602+0000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2020-03-31 23:55:31.0</td>\n",
       "      <td>I beat my own record! The new one is 52!!! @US...</td>\n",
       "      <td>http://twitter.com/reesebatesvb/statuses/12451...</td>\n",
       "      <td>en</td>\n",
       "      <td>reesebatesvb</td>\n",
       "      <td>https://audiences.brandwatch.com/api/audiences...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>Kansas City</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>30</td>\n",
       "      <td>79</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>24</td>\n",
       "      <td>False</td>\n",
       "      <td>2020-10-05T16:39:32.631+0000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 41 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                    Date                                              Title  \\\n",
       "0  2020-03-31 23:58:48.0  @TeamUSA Literally all of the 2012 Olympics fo...   \n",
       "1  2020-03-31 23:57:17.0  @LanderVBALL @reesebatesvb @vbcoch @USAVBeach ...   \n",
       "2  2020-03-31 23:57:00.0  \"To be blunt, it started women's basketball in...   \n",
       "3  2020-03-31 23:56:25.0  @DetroitHandball @TeamHandball @USATH @USARugb...   \n",
       "4  2020-03-31 23:55:31.0  I beat my own record! The new one is 52!!! @US...   \n",
       "\n",
       "                                                 Url Language        Author  \\\n",
       "0  http://twitter.com/arv5518/statuses/1245138508...       en       arv5518   \n",
       "1  http://twitter.com/alexptck3/statuses/12451381...       en     alexptck3   \n",
       "2  http://twitter.com/NBCOlympics/statuses/124513...       en   NBCOlympics   \n",
       "3  http://twitter.com/CoachJax11/statuses/1245137...       en    CoachJax11   \n",
       "4  http://twitter.com/reesebatesvb/statuses/12451...       en  reesebatesvb   \n",
       "\n",
       "                                              Avatar  Category Details  \\\n",
       "0  https://audiences.brandwatch.com/api/audiences...               NaN   \n",
       "1  https://audiences.brandwatch.com/api/audiences...               NaN   \n",
       "2  https://audiences.brandwatch.com/api/audiences...               NaN   \n",
       "3  https://audiences.brandwatch.com/api/audiences...               NaN   \n",
       "4  https://audiences.brandwatch.com/api/audiences...               NaN   \n",
       "\n",
       "   Checked         City  Display URLs  ... Twitter Followers  \\\n",
       "0    False          NaN           NaN  ...                 3   \n",
       "1    False          NaN           NaN  ...               217   \n",
       "2    False          NaN           NaN  ...            922572   \n",
       "3    False          NaN           NaN  ...               158   \n",
       "4    False  Kansas City           NaN  ...                30   \n",
       "\n",
       "  Twitter Following Twitter Reply Count  \\\n",
       "0                76                   0   \n",
       "1               293                   1   \n",
       "2              2991                   2   \n",
       "3               249                   1   \n",
       "4                79                   0   \n",
       "\n",
       "                                    Twitter Reply to Twitter Retweet of  \\\n",
       "0  http://twitter.com/TeamUSA/statuses/1245063460...                NaN   \n",
       "1  http://twitter.com/LanderVBALL/statuses/124511...                NaN   \n",
       "2                                                NaN                NaN   \n",
       "3  http://twitter.com/DetroitHandball/statuses/12...                NaN   \n",
       "4                                                NaN                NaN   \n",
       "\n",
       "   Twitter Retweets  Twitter Tweets  Twitter Verified  \\\n",
       "0                 0             345             False   \n",
       "1                 0            1600             False   \n",
       "2                61           32017              True   \n",
       "3                 0             792             False   \n",
       "4                 1              24             False   \n",
       "\n",
       "                        Updated  Reach (new)  \n",
       "0  2020-10-05T16:39:32.631+0000            0  \n",
       "1  2020-10-05T16:39:32.613+0000            9  \n",
       "2  2020-10-05T16:39:32.615+0000        67412  \n",
       "3  2020-10-05T16:39:32.602+0000            0  \n",
       "4  2020-10-05T16:39:32.631+0000            0  \n",
       "\n",
       "[5 rows x 41 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "oly = pd.read_csv('Olympics-Twitter.csv')\n",
    "oly.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(Index(['Date', 'Title', 'Url', 'Language', 'Author', 'Avatar',\n",
       "        'Category Details', 'Checked', 'City', 'Display URLs', 'Expanded URLs',\n",
       "        'Full Name', 'Full Text', 'Gender', 'Hashtags', 'Impact', 'Impressions',\n",
       "        'Latitude', 'Location Name', 'Longitude', 'Media Filter', 'Media URLs',\n",
       "        'Mentioned Authors', 'Original Url', 'Thread Author',\n",
       "        'Thread Created Date', 'Thread Entry Type', 'Thread Id', 'Thread URL',\n",
       "        'Twitter Author ID', 'Twitter Channel Role', 'Twitter Followers',\n",
       "        'Twitter Following', 'Twitter Reply Count', 'Twitter Reply to',\n",
       "        'Twitter Retweet of', 'Twitter Retweets', 'Twitter Tweets',\n",
       "        'Twitter Verified', 'Updated', 'Reach (new)'],\n",
       "       dtype='object'),\n",
       " (19714, 41))"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(oly.columns, oly.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"@TeamUSA Literally all of the 2012 Olympics for women's artistic gymnastics\""
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "oly['Full Text'].iloc[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"@teamusa literally all of the 2012 olympics for women's artistic gymnastics\""
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sometext = oly['Full Text'].iloc[0]\n",
    "sometext.lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"@TEAMUSA LITERALLY ALL OF THE 2012 OLYMPICS FOR WOMEN'S ARTISTIC GYMNASTICS\""
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sometext.upper()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"@Teamusa Literally All Of The 2012 Olympics For Women'S Artistic Gymnastics\""
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sometext.title()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"@TeamUSA Literally all of the 2012 Olympics for women's artistic gymnastics\""
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sometext.strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['@TeamUSA',\n",
       " 'Literally',\n",
       " 'all',\n",
       " 'of',\n",
       " 'the',\n",
       " '2012',\n",
       " 'Olympics',\n",
       " 'for',\n",
       " \"women's\",\n",
       " 'artistic',\n",
       " 'gymnastics']"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sometext.split()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "@TeamUSA\n",
      "Literally\n",
      "all\n",
      "of\n",
      "the\n",
      "2012\n",
      "Olympics\n",
      "for\n",
      "women's\n",
      "artistic\n",
      "gymnastics\n"
     ]
    }
   ],
   "source": [
    "for i in sometext.split():\n",
    "    lemma = nltk.stem.wordnet.WordNetLemmatizer().lemmatize(i)\n",
    "    print(lemma)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sometimes\n",
      "dog\n",
      "walked\n",
      "toward\n",
      "house\n",
      "on\n",
      "weekday\n"
     ]
    }
   ],
   "source": [
    "othertext = ['Sometimes', 'dogs', 'walked', 'toward', 'houses', 'on', 'weekdays']\n",
    "for i in othertext:\n",
    "    lemma = nltk.stem.wordnet.WordNetLemmatizer().lemmatize(i)\n",
    "    print(lemma)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Apple is looking at buying U.K. startup for $1 billion\n",
      "Apple PROPN nsubj\n",
      "is AUX aux\n",
      "looking VERB ROOT\n",
      "at ADP prep\n",
      "buying VERB pcomp\n",
      "U.K. PROPN dobj\n",
      "startup NOUN dep\n",
      "for ADP prep\n",
      "$ SYM quantmod\n",
      "1 NUM compound\n",
      "billion NUM pobj\n"
     ]
    }
   ],
   "source": [
    "from spacy.lang.en.examples import sentences \n",
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "doc = nlp(sentences[0])\n",
    "print(doc.text)\n",
    "for token in doc:\n",
    "    print(token.text, token.pos_, token.dep_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "@TeamUSA Literally all of the 2012 Olympics for women's artistic gymnastics\n",
      "@TeamUSA PROPN ROOT\n",
      "Literally ADV advmod\n",
      "all PRON npadvmod\n",
      "of ADP prep\n",
      "the DET det\n",
      "2012 NUM nummod\n",
      "Olympics PROPN pobj\n",
      "for ADP prep\n",
      "women NOUN poss\n",
      "'s PART case\n",
      "artistic ADJ amod\n",
      "gymnastics NOUN pobj\n"
     ]
    }
   ],
   "source": [
    "twt = nlp(sometext)\n",
    "print(twt.text)\n",
    "for token in twt:\n",
    "    print(token.text, token.pos_, token.dep_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "False False True dogs ogs\n"
     ]
    }
   ],
   "source": [
    "print(nlp('dogs')[0].orth_.isspace(),\n",
    "      nlp('dogs')[0].like_url,\n",
    "      nlp('dogs')[0].orth_.startswith('d'),\n",
    "      nlp('dogs')[0].lower_,\n",
    "      nlp('dogs')[0].orth_[1:]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['TeamUSA',\n",
       " 'literally',\n",
       " 'all',\n",
       " 'of',\n",
       " 'the',\n",
       " '2012',\n",
       " 'olympics',\n",
       " 'for',\n",
       " 'women',\n",
       " \"'s\",\n",
       " 'artistic',\n",
       " 'gymnastics']"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lda_tokens = []\n",
    "tokens = nlp(sometext)\n",
    "for token in tokens:\n",
    "    if token.orth_.isspace():\n",
    "        continue\n",
    "    elif token.like_url:\n",
    "        lda_tokens.append('URL')\n",
    "    elif token.orth_.startswith('@'):\n",
    "        lda_tokens.append(token.orth_[1:])\n",
    "    else:\n",
    "        lda_tokens.append(token.lower_)\n",
    "\n",
    "lda_tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize(text):\n",
    "    lda_tokens = []\n",
    "    tokens = nlp(text)\n",
    "    for token in tokens:\n",
    "        if token.orth_.isspace():\n",
    "            continue\n",
    "        elif token.like_url:\n",
    "            lda_tokens.append('URL')\n",
    "        elif token.orth_.startswith('@'):\n",
    "            lda_tokens.append(token.orth_[1:])\n",
    "        else:\n",
    "            lda_tokens.append(token.lower_)\n",
    "    return lda_tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['TeamUSA',\n",
       " 'literally',\n",
       " 'all',\n",
       " 'of',\n",
       " 'the',\n",
       " '2012',\n",
       " 'olympics',\n",
       " 'for',\n",
       " 'women',\n",
       " \"'s\",\n",
       " 'artistic',\n",
       " 'gymnastics']"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "somedoc = tokenize(sometext)\n",
    "somedoc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['TeamUSA', 'literally', 'olympics', 'women', 'artistic', 'gymnastics']"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[token for token in somedoc if len(token) > 4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['i', 'me', 'my', 'myself', 'we', 'our', 'ours', 'ourselves', 'you', \"you're\"]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "en_stop = nltk.corpus.stopwords.words('english')\n",
    "en_stop[0:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[@TeamUSA,\n",
       " Literally,\n",
       " all,\n",
       " of,\n",
       " the,\n",
       " 2012,\n",
       " Olympics,\n",
       " for,\n",
       " women,\n",
       " 's,\n",
       " artistic,\n",
       " gymnastics]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[token for token in tokens if somedoc not in en_stop]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['TeamUSA',\n",
       " 'literally',\n",
       " 'all',\n",
       " 'of',\n",
       " 'the',\n",
       " '2012',\n",
       " 'olympics',\n",
       " 'for',\n",
       " 'woman',\n",
       " \"'s\",\n",
       " 'artistic',\n",
       " 'gymnastics']"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_lemma = nltk.stem.wordnet.WordNetLemmatizer().lemmatize\n",
    "# get_lemma = nltk.corpus.wordnet.morphy\n",
    "[get_lemma(token) for token in somedoc]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_text(text):\n",
    "    tokens = tokenize(text)\n",
    "    tokens = [token for token in tokens if len(token) > 2] # manipulate this\n",
    "    tokens = [token for token in tokens if token not in en_stop]\n",
    "    tokens = [get_lemma(token) for token in tokens]\n",
    "    return tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "twt_data = []\n",
    "for tweet in oly['Full Text'][:100]:\n",
    "    twt_data.append(prepare_text(tweet))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['TeamUSA', 'literally', '2012', 'olympics', 'woman', 'artistic', 'gymnastics']\n",
      "['LanderVBALL', 'reesebatesvb', 'vbcoch', 'USAVBeach', 'usavolleyball', 'MadiReed42', 'nell_copeland', 'omg', 'going', 'try', 'need', 'find', 'another', 'ball']\n",
      "['blunt', 'started', 'woman', 'basketball', 'country', 'gave', 'notoriety', 'deserved', '-@s10bird', 'close', 'womenshistorymonth', 'celebrating', 'team', 'started', 'dynasty', '1996', 'woman', 'usabasketball', 'URL']\n",
      "['DetroitHandball', 'TeamHandball', 'USATH', 'USARugby', 'still', 'love']\n",
      "['beat', 'record', 'new', 'one', 'USAVBeach', 'usavolleyball', 'FIVBBeach', 'FIVBVolleyball', 'OleMissVB', 'NEVBProbs', 'FAUVolleyball', 'FGCU_VB', 'CreightonVB', 'StanfordWVB', 'KUVolleyball', 'URL']\n"
     ]
    }
   ],
   "source": [
    "for i in twt_data[0:5]:\n",
    "    print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "@TeamUSA Literally all of the 2012 Olympics for women's artistic gymnastics\n",
      "@LanderVBALL @reesebatesvb @vbcoch @USAVBeach @usavolleyball @MadiReed42 @nell_copeland Omg I am going to try this! Now I just need to find another ballðŸ¤”\n",
      "\"To be blunt, it started women's basketball in this country. It gave it the notoriety it deserved.\" -@s10bird We close #WomensHistoryMonth by celebrating the team that started a DYNASTY: The 1996 women of @usabasketball. https://t.co/TI5wWOtjtP\n",
      "@DetroitHandball @TeamHandball @USATH @USARugby I still love u\n",
      "I beat my own record! The new one is 52!!! @USAVBeach @usavolleyball @FIVBBeach @FIVBVolleyball @OleMissVB @NEVBProbs @FAUVolleyball @FGCU_VB @CreightonVB @StanfordWVB @KUVolleyball https://t.co/rXutjelgxs\n"
     ]
    }
   ],
   "source": [
    "for i in oly['Full Text'][0:5]:\n",
    "    print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<gensim.corpora.dictionary.Dictionary at 0x26ee73b5250>"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dictionary = gensim.corpora.Dictionary(twt_data)\n",
    "dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(0, 1), (1, 1), (2, 1), (3, 1), (4, 1), (5, 1), (6, 1)]\n",
      "[(7, 1), (8, 1), (9, 1), (10, 1), (11, 1), (12, 1), (13, 1), (14, 1), (15, 1), (16, 1), (17, 1), (18, 1), (19, 1), (20, 1)]\n",
      "[(6, 2), (21, 1), (22, 1), (23, 1), (24, 1), (25, 1), (26, 1), (27, 1), (28, 1), (29, 1), (30, 1), (31, 1), (32, 1), (33, 2), (34, 1), (35, 1), (36, 1)]\n",
      "[(37, 1), (38, 1), (39, 1), (40, 1), (41, 1), (42, 1)]\n"
     ]
    }
   ],
   "source": [
    "corpus = [dictionary.doc2bow(text) for text in twt_data]\n",
    "for i in corpus[0:4]:\n",
    "    print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(0,\n",
       "  '0.051*\"URL\" + 0.017*\"USATH\" + 0.017*\"TeamHandball\" + 0.017*\"USARugby\" + 0.014*\"TeamUSA\"'),\n",
       " (1,\n",
       "  '0.059*\"TeamUSA\" + 0.015*\"miracle\" + 0.013*\"URL\" + 0.013*\"ice\" + 0.013*\"1980\"'),\n",
       " (2,\n",
       "  '0.015*\"USWNT\" + 0.014*\"TeamUSA\" + 0.010*\"...\" + 0.010*\"FIFAcom\" + 0.010*\"calUSAwrestling\"'),\n",
       " (3,\n",
       "  '0.025*\"USWNT\" + 0.024*\"samanthabarry\" + 0.024*\"glamourmag\" + 0.024*\"alexmorgan13\" + 0.015*\"good\"'),\n",
       " (4,\n",
       "  '0.022*\"TeamUSA\" + 0.017*\"URL\" + 0.017*\"Tokyo2020\" + 0.013*\"woman\" + 0.013*\"usabasketball\"')]"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ldamodel = gensim.models.ldamodel.LdaModel(corpus, num_topics = 5, id2word=dictionary, passes=15)\n",
    "ldamodel.print_topics(num_words = 5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Many more elements to extract from ldamodel objects at: https://radimrehurek.com/gensim/models/ldamodel.html#gensim.models.ldamodel.LdaModel.do_estep"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(0, 0.011882239),\n",
       " (1, 0.011805542),\n",
       " (2, 0.011809051),\n",
       " (3, 0.011833897),\n",
       " (4, 0.95266926)]"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ldamodel.get_document_topics(corpus[4])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "indata_fa24",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
